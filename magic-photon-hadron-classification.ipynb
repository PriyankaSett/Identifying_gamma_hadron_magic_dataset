{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-29T09:48:45.743979Z","iopub.execute_input":"2023-03-29T09:48:45.744442Z","iopub.status.idle":"2023-03-29T09:48:45.765879Z","shell.execute_reply.started":"2023-03-29T09:48:45.744406Z","shell.execute_reply":"2023-03-29T09:48:45.764516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib as plt\n%matplotlib inline\npd.pandas.set_option('display.max_rows', None)\n\nfrom matplotlib import *\nimport sys\nfrom pylab import *\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:45.768652Z","iopub.execute_input":"2023-03-29T09:48:45.769356Z","iopub.status.idle":"2023-03-29T09:48:45.782011Z","shell.execute_reply.started":"2023-03-29T09:48:45.769309Z","shell.execute_reply":"2023-03-29T09:48:45.780713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data:\nhttps://www.kaggle.com/datasets/abhinand05/magic-gamma-telescope-dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/magic-gamma-telescope-dataset/telescope_data.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:45.783703Z","iopub.execute_input":"2023-03-29T09:48:45.784956Z","iopub.status.idle":"2023-03-29T09:48:45.830755Z","shell.execute_reply.started":"2023-03-29T09:48:45.784863Z","shell.execute_reply":"2023-03-29T09:48:45.829260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:45.833452Z","iopub.execute_input":"2023-03-29T09:48:45.834652Z","iopub.status.idle":"2023-03-29T09:48:45.861994Z","shell.execute_reply.started":"2023-03-29T09:48:45.834605Z","shell.execute_reply":"2023-03-29T09:48:45.860420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic information about data set","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:45.863961Z","iopub.execute_input":"2023-03-29T09:48:45.864414Z","iopub.status.idle":"2023-03-29T09:48:45.875285Z","shell.execute_reply.started":"2023-03-29T09:48:45.864374Z","shell.execute_reply":"2023-03-29T09:48:45.873797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:45.877295Z","iopub.execute_input":"2023-03-29T09:48:45.877766Z","iopub.status.idle":"2023-03-29T09:48:45.889104Z","shell.execute_reply.started":"2023-03-29T09:48:45.877726Z","shell.execute_reply":"2023-03-29T09:48:45.887680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:45.890352Z","iopub.execute_input":"2023-03-29T09:48:45.890803Z","iopub.status.idle":"2023-03-29T09:48:45.910773Z","shell.execute_reply.started":"2023-03-29T09:48:45.890758Z","shell.execute_reply":"2023-03-29T09:48:45.909664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**All the features have numerical data except the last one.**","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:45.912002Z","iopub.execute_input":"2023-03-29T09:48:45.912705Z","iopub.status.idle":"2023-03-29T09:48:45.925608Z","shell.execute_reply.started":"2023-03-29T09:48:45.912672Z","shell.execute_reply":"2023-03-29T09:48:45.924302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**No null values.**","metadata":{}},{"cell_type":"code","source":"df['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:45.928909Z","iopub.execute_input":"2023-03-29T09:48:45.929267Z","iopub.status.idle":"2023-03-29T09:48:45.941987Z","shell.execute_reply.started":"2023-03-29T09:48:45.929237Z","shell.execute_reply":"2023-03-29T09:48:45.940892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"~ 35% is hadron data and 65% is gamma data.. ","metadata":{}},{"cell_type":"code","source":"df2 = df.copy()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:45.944454Z","iopub.execute_input":"2023-03-29T09:48:45.944895Z","iopub.status.idle":"2023-03-29T09:48:45.951692Z","shell.execute_reply.started":"2023-03-29T09:48:45.944854Z","shell.execute_reply":"2023-03-29T09:48:45.950426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:45.953081Z","iopub.execute_input":"2023-03-29T09:48:45.953514Z","iopub.status.idle":"2023-03-29T09:48:45.978761Z","shell.execute_reply.started":"2023-03-29T09:48:45.953468Z","shell.execute_reply":"2023-03-29T09:48:45.977237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Converting the categorical variable.","metadata":{}},{"cell_type":"code","source":"# we can label encode the class feature. \n\n\"\"\"\nIn this notebook we are denoting gamma event as '1' as that is our prime concern. \nAs gamma is label encoded as '1' and we need to do a \nprecise measurement for gamma, in this problem we will consider 'precision' as evaluation metric. \n\nOne can also the other way around. In that case 'recall' should be the evaluation metric.\n\"\"\" \n\ndf2['class1'] = df2['class'].map({'g' : '1', 'h' : '0'})\ndf2['class1'] = df2['class1'].astype(int)\ndf2.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:45.983499Z","iopub.execute_input":"2023-03-29T09:48:45.983969Z","iopub.status.idle":"2023-03-29T09:48:47.367628Z","shell.execute_reply.started":"2023-03-29T09:48:45.983888Z","shell.execute_reply":"2023-03-29T09:48:47.366288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df2.copy()\n\n# dropping the first column \n\ndata.drop('Unnamed: 0', axis = 1, inplace = True)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:47.369842Z","iopub.execute_input":"2023-03-29T09:48:47.370443Z","iopub.status.idle":"2023-03-29T09:48:47.395622Z","shell.execute_reply.started":"2023-03-29T09:48:47.370408Z","shell.execute_reply":"2023-03-29T09:48:47.394298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featlist = data.columns\nfeatlist","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:47.396958Z","iopub.execute_input":"2023-03-29T09:48:47.397756Z","iopub.status.idle":"2023-03-29T09:48:47.405886Z","shell.execute_reply.started":"2023-03-29T09:48:47.397721Z","shell.execute_reply":"2023-03-29T09:48:47.404483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic EDA","metadata":{}},{"cell_type":"code","source":"#checking the histograms for each feature\nfig, axes = plt.subplots(3,4, figsize=(15,12) )\nsi1 = [[0,0], [0,1], [0,2], [0,3], [1,0], [1,1], [1,2], [1,3],  [2,0], [2,1], [2,2], [2,3]]\n\nfor item in range(len(featlist)-2): \n    i = si1[item][0]\n    j = si1[item][1]\n    sns.distplot(data[featlist[item]], kde = True, ax =axes[i,j])    \n    \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:47.407383Z","iopub.execute_input":"2023-03-29T09:48:47.407755Z","iopub.status.idle":"2023-03-29T09:48:51.676198Z","shell.execute_reply.started":"2023-03-29T09:48:47.407723Z","shell.execute_reply":"2023-03-29T09:48:51.674738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.corr()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:51.677761Z","iopub.execute_input":"2023-03-29T09:48:51.678246Z","iopub.status.idle":"2023-03-29T09:48:51.710585Z","shell.execute_reply.started":"2023-03-29T09:48:51.678206Z","shell.execute_reply":"2023-03-29T09:48:51.709328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(data, hue = 'class', hue_order = ['h', 'g'])","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:48:51.713904Z","iopub.execute_input":"2023-03-29T09:48:51.714568Z","iopub.status.idle":"2023-03-29T09:51:36.070546Z","shell.execute_reply.started":"2023-03-29T09:48:51.714520Z","shell.execute_reply":"2023-03-29T09:51:36.065861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**  \nWe already know that this dataset has more gamma data than hadron data. This scenario is very much unlikely in real experiment. We will handle this behavior later. \n\nFor now, looking at the pairplot, it is observed that the blue and \nyellow points are overlapped. So, we can try to proceed with Decision Trees and Ensemble techniques. If this does not work good, we can try upsampling/downsampling or SMOTE. ","metadata":{}},{"cell_type":"code","source":"# let us explore all the features as a function of class1\n\nfig, axes = plt.subplots(3,4, figsize=(16,12), tight_layout = True )\nsi1 = [[0,0], [0,1], [0,2], [0,3], \n       [1,0], [1,1], [1,2], [1,3], \n       [2,0], [2,1], [2,2], [2,3]]\n\nfor item in range(len(featlist)-2): \n    i = si1[item][0]\n    j = si1[item][1]\n    sns.histplot(data = data, hue = 'class1', x = featlist[item], ax =axes[i,j])\n    axes[i,j].set_title(f'class vs {featlist[item]}')\n    axes[i,j].set_xlabel('class')\n    axes[i,j].set_ylabel(featlist[item])\n    \n    \nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:51:36.075620Z","iopub.execute_input":"2023-03-29T09:51:36.076277Z","iopub.status.idle":"2023-03-29T09:51:44.756540Z","shell.execute_reply.started":"2023-03-29T09:51:36.076232Z","shell.execute_reply":"2023-03-29T09:51:44.755692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(data.corr(), annot = True)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:51:44.757703Z","iopub.execute_input":"2023-03-29T09:51:44.758611Z","iopub.status.idle":"2023-03-29T09:51:46.944280Z","shell.execute_reply.started":"2023-03-29T09:51:44.758563Z","shell.execute_reply":"2023-03-29T09:51:46.943021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us try to understand the data in detail. Let us try to study the correlation \namong the parameters for hadrons and gamma seperately. ","metadata":{}},{"cell_type":"markdown","source":"### Some more EDA for gamma and hadron seperately","metadata":{}},{"cell_type":"code","source":"#data_gamma = data[[data['class1'] == 1]]\n#data_gamma.head()\n\ndata_gamma = data[data['class1']==1]\ndata_gamma.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:51:46.945938Z","iopub.execute_input":"2023-03-29T09:51:46.946352Z","iopub.status.idle":"2023-03-29T09:51:46.956682Z","shell.execute_reply.started":"2023-03-29T09:51:46.946319Z","shell.execute_reply":"2023-03-29T09:51:46.955221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(data_gamma)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:51:46.958325Z","iopub.execute_input":"2023-03-29T09:51:46.958675Z","iopub.status.idle":"2023-03-29T09:52:28.187927Z","shell.execute_reply.started":"2023-03-29T09:51:46.958644Z","shell.execute_reply":"2023-03-29T09:52:28.186596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure(figsize = (8,8))\nsns.heatmap(data_gamma.corr(), annot = True, cmap = 'RdYlGn')","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:52:28.189654Z","iopub.execute_input":"2023-03-29T09:52:28.190133Z","iopub.status.idle":"2023-03-29T09:52:29.040247Z","shell.execute_reply.started":"2023-03-29T09:52:28.190097Z","shell.execute_reply":"2023-03-29T09:52:29.038971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_hadron = data[data['class1'] == 0]\ndata_hadron.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:52:29.041748Z","iopub.execute_input":"2023-03-29T09:52:29.042238Z","iopub.status.idle":"2023-03-29T09:52:29.052309Z","shell.execute_reply.started":"2023-03-29T09:52:29.042061Z","shell.execute_reply":"2023-03-29T09:52:29.051270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(data_hadron)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:52:29.055969Z","iopub.execute_input":"2023-03-29T09:52:29.056371Z","iopub.status.idle":"2023-03-29T09:53:12.366703Z","shell.execute_reply.started":"2023-03-29T09:52:29.056330Z","shell.execute_reply":"2023-03-29T09:53:12.365565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure(figsize = (10,10))\nsns.heatmap(data_hadron.corr(), annot = True, cmap = 'RdYlGn')","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:12.368043Z","iopub.execute_input":"2023-03-29T09:53:12.369037Z","iopub.status.idle":"2023-03-29T09:53:13.188285Z","shell.execute_reply.started":"2023-03-29T09:53:12.368999Z","shell.execute_reply":"2023-03-29T09:53:13.187324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Building\n\n- This problem in reality is a rare event detection. In the problem statement itself it was given that in this data set the gamma event are much more than the hadron event. This data set we have 65% gamma event and 35% hadron event.  But in practise, this is not the scenario.  The main aim is to detect gamma in a sea of hadrons. In this cases, it is very well established method to train the data on equal number of samples and then test on the test data. i.e, we will upsample the hadron data or downsample the gamma data so that there are same numbers of tagged data for hadrons and gamma. With these upsampled/downsampled data we will train the model and use the actual test data to predict and study the metric. Before performing upsampling/downsampling we would like to investige about which algorithm performs the task better.\n\n- Let's start model building. We will go ahead with RandomForestClassifier, AdaBoost, GradientBoost and XgBoost .","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier \nimport xgboost as xgb \nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, roc_curve","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:13.189436Z","iopub.execute_input":"2023-03-29T09:53:13.190424Z","iopub.status.idle":"2023-03-29T09:53:13.195628Z","shell.execute_reply.started":"2023-03-29T09:53:13.190388Z","shell.execute_reply":"2023-03-29T09:53:13.194711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data[['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long',\n       'fM3Trans', 'fAlpha', 'fDist']]\ny = data[['class1']]\n\nprint(X.head(2))\nprint(y.head(2))\nprint(X.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:13.197574Z","iopub.execute_input":"2023-03-29T09:53:13.197944Z","iopub.status.idle":"2023-03-29T09:53:13.219384Z","shell.execute_reply.started":"2023-03-29T09:53:13.197914Z","shell.execute_reply":"2023-03-29T09:53:13.218114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:13.220832Z","iopub.execute_input":"2023-03-29T09:53:13.221323Z","iopub.status.idle":"2023-03-29T09:53:13.238670Z","shell.execute_reply.started":"2023-03-29T09:53:13.221278Z","shell.execute_reply":"2023-03-29T09:53:13.237222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Shape of Training data : {X_train.shape}, {y_train.shape}')\nprint(f'Shape of Test data : {X_test.shape}{y_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:13.240307Z","iopub.execute_input":"2023-03-29T09:53:13.240746Z","iopub.status.idle":"2023-03-29T09:53:13.248117Z","shell.execute_reply.started":"2023-03-29T09:53:13.240694Z","shell.execute_reply":"2023-03-29T09:53:13.246913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first let's try with RandomForest Classifier: \n\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\npred_rf = rf.predict(X_test)\npred_prob_rf = rf.predict_proba(X_test)[:, 0]\npred_prob_rf_gamma = rf.predict_proba(X_test)[:, 1]\n\nprint(classification_report(y_test, pred_rf))\nprint(confusion_matrix(y_test, pred_rf))","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:13.250048Z","iopub.execute_input":"2023-03-29T09:53:13.250520Z","iopub.status.idle":"2023-03-29T09:53:18.731533Z","shell.execute_reply.started":"2023-03-29T09:53:13.250474Z","shell.execute_reply":"2023-03-29T09:53:18.730221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abc = AdaBoostClassifier()\nabc.fit(X_train, y_train)\npred_abc = abc.predict(X_test)\npred_prob_abc = abc.predict_proba(X_test)[:, 0]\npred_prob_abc_gamma = abc.predict_proba(X_test)[:, 1] \n\nprint(classification_report(y_test, pred_abc))\nprint(confusion_matrix(y_test, pred_abc))","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:18.734132Z","iopub.execute_input":"2023-03-29T09:53:18.735227Z","iopub.status.idle":"2023-03-29T09:53:20.117468Z","shell.execute_reply.started":"2023-03-29T09:53:18.735180Z","shell.execute_reply":"2023-03-29T09:53:20.116314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc = GradientBoostingClassifier()\ngbc.fit(X_train, y_train)\npred_gbc = gbc.predict(X_test)\npred_prob_gbc = gbc.predict_proba(X_test)[:, 0]\npred_prob_gbc_gamma = gbc.predict_proba(X_test)[:, 1]\n\nprint(classification_report(y_test, pred_gbc))\nprint(confusion_matrix(y_test, pred_gbc))","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:20.118756Z","iopub.execute_input":"2023-03-29T09:53:20.119065Z","iopub.status.idle":"2023-03-29T09:53:24.979740Z","shell.execute_reply.started":"2023-03-29T09:53:20.119036Z","shell.execute_reply":"2023-03-29T09:53:24.978372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's try with XgBoost: \n\nxb = xgb.XGBRFClassifier()\nxb.fit(X_train, y_train)\npred_xb = xb.predict(X_test)\npred_prob_xb = xb.predict_proba(X_test)[:,0]\npred_prob_xb_gamma = xb.predict_proba(X_test)[:, 1]\n\nprint(classification_report(y_test, pred_xb))\nprint(confusion_matrix(y_test, pred_xb))","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:24.981791Z","iopub.execute_input":"2023-03-29T09:53:24.982274Z","iopub.status.idle":"2023-03-29T09:53:26.431237Z","shell.execute_reply.started":"2023-03-29T09:53:24.982221Z","shell.execute_reply":"2023-03-29T09:53:26.430407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ROC curve :","metadata":{}},{"cell_type":"code","source":"# plotting roc curve and finding auc score : \n\n\n# hadrons :\nrf_fpr, rf_tpr, rf_threshold = roc_curve(y_test, pred_prob_rf, pos_label=0)\nabc_fpr, abc_tpr, abc_threshold = roc_curve(y_test, pred_prob_abc, pos_label=0)\ngbc_fpr, gbc_tpr, gbc_threshold = roc_curve(y_test, pred_prob_gbc, pos_label=0)\nxb_fpr, xb_tpr, xb_threshold = roc_curve(y_test, pred_prob_xb, pos_label=0)\n\n\n# gammas:\nrf_fpr_g, rf_tpr_g, rf_threshold_g = roc_curve(y_test, pred_prob_rf_gamma, pos_label=1)\nabc_fpr_g, abc_tpr_g, abc_threshold_g = roc_curve(y_test, pred_prob_abc_gamma, pos_label=1)\ngbc_fpr_g, gbc_tpr_g, gbc_threshold_g = roc_curve(y_test, pred_prob_gbc_gamma, pos_label=1)\nxb_fpr_g, xb_tpr_g, xb_threshold_g = roc_curve(y_test, pred_prob_xb_gamma, pos_label=1)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:26.432617Z","iopub.execute_input":"2023-03-29T09:53:26.433208Z","iopub.status.idle":"2023-03-29T09:53:26.453939Z","shell.execute_reply.started":"2023-03-29T09:53:26.433165Z","shell.execute_reply":"2023-03-29T09:53:26.452550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(rf_fpr, rf_tpr, color  = 'red', label='Random Forest Classifier')\nplt.plot(abc_fpr, abc_tpr, color  = 'blue', label='AdaBoost Classifier')\nplt.plot(gbc_fpr, gbc_tpr, color  = 'cyan', label = 'Gradient Boosting Classifier')\nplt.plot(xb_fpr, xb_tpr, color  = 'green', label = 'XgBoost Classifier')\nplt.title('Hadrons')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.grid()\nplt.show()\n\n\nplt.plot(rf_fpr_g, rf_tpr_g, color  = 'red', label='Random Forest Classifier')\nplt.plot(abc_fpr_g, abc_tpr_g, color  = 'blue', label='AdaBoost Classifier')\nplt.plot(gbc_fpr_g, gbc_tpr_g, color  = 'cyan', label = 'Gradient Boosting Classifier')\nplt.plot(xb_fpr_g, xb_tpr_g, color  = 'green', label = 'XgBoost Classifier')\nplt.title('Gammas')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.grid()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:26.455670Z","iopub.execute_input":"2023-03-29T09:53:26.456395Z","iopub.status.idle":"2023-03-29T09:53:27.090349Z","shell.execute_reply.started":"2023-03-29T09:53:26.456350Z","shell.execute_reply":"2023-03-29T09:53:27.089419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### AUC score:","metadata":{}},{"cell_type":"code","source":"# auc score : \nauc_rf = roc_auc_score(y_test, pred_prob_rf_gamma)\nauc_abc = roc_auc_score(y_test, pred_prob_abc_gamma)\nauc_gbc = roc_auc_score(y_test, pred_prob_gbc_gamma)\nauc_xb = roc_auc_score(y_test, pred_prob_xb_gamma)\n\nprint(f'Auc score for Random Forest Classifier : {round(auc_rf, 3)}')\nprint(f'Auc score for AdaBoost Classifier : {round(auc_abc, 3)}')\nprint(f'Auc score for Gradient Boosting : {round(auc_gbc, 3)}')\nprint(f'Auc score for XgBoost Classifier : {round(auc_xb, 3)}')\n","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:27.097157Z","iopub.execute_input":"2023-03-29T09:53:27.097831Z","iopub.status.idle":"2023-03-29T09:53:27.124037Z","shell.execute_reply.started":"2023-03-29T09:53:27.097796Z","shell.execute_reply":"2023-03-29T09:53:27.123113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Precision - Recall Curve: \n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\n\nprecision_rf1, recall_rf1, threshold_rf1 = precision_recall_curve(y_test, pred_prob_rf, pos_label = 0)\nprecision_rf0, recall_rf0, threshold_rf0 = precision_recall_curve(y_test, pred_prob_rf_gamma, pos_label = 1)\n\n\nprecision_abc1, recall_abc1, threshold_abc1 = precision_recall_curve(y_test, pred_prob_abc, pos_label = 0)\nprecision_abc0, recall_abc0, threshold_abc0 = precision_recall_curve(y_test, pred_prob_abc_gamma, pos_label = 1)\n\nprecision_gbc1, recall_gbc1, threshold_gbc1 = precision_recall_curve(y_test, pred_prob_gbc, pos_label = 0)\nprecision_gbc0, recall_gbc0, threshold_gbc0 = precision_recall_curve(y_test, pred_prob_gbc_gamma, pos_label = 1)\n\nprecision_xb1, recall_xb1, threshold_xb1 = precision_recall_curve(y_test, pred_prob_xb, pos_label = 0)\nprecision_xb0, recall_xb0, threshold_xb0 = precision_recall_curve(y_test, pred_prob_xb_gamma, pos_label = 1)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:27.125548Z","iopub.execute_input":"2023-03-29T09:53:27.126753Z","iopub.status.idle":"2023-03-29T09:53:27.149006Z","shell.execute_reply.started":"2023-03-29T09:53:27.126708Z","shell.execute_reply":"2023-03-29T09:53:27.148090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\n\nplt.plot(precision_rf1, recall_rf1, color='red', label='RF - Hadrons')\nplt.plot(precision_rf0, recall_rf0, color='red', linestyle = 'dashed' , label='RF - Gammas')\n\nplt.plot(precision_abc1, recall_abc1, color='blue', label='Ada Boost - Hadrons')\nplt.plot(precision_abc0, recall_abc0, color='blue', linestyle = 'dashed' , label='Ada Boost - Gammas')\n\nplt.plot(precision_gbc1, recall_gbc1, color='cyan', label='Grad. Boosting - Hadrons')\nplt.plot(precision_gbc0, recall_gbc0, color='cyan', linestyle = 'dashed' , label='Grad. Boosting - Gammas')\n\nplt.plot(precision_xb1, recall_xb1, color='green', label='Xgboost - Hadrons')\nplt.plot(precision_xb0, recall_xb0, color='green', linestyle = 'dashed' , label='Xgboost - Gammas')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend(loc=\"lower left\")\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:27.153082Z","iopub.execute_input":"2023-03-29T09:53:27.153526Z","iopub.status.idle":"2023-03-29T09:53:27.523699Z","shell.execute_reply.started":"2023-03-29T09:53:27.153492Z","shell.execute_reply":"2023-03-29T09:53:27.522510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations from different models:   \n- In this problem our goal is to identify gammas as many as we can. In that case, \nall the above Models are working pretty good. The ROC curve and AUC scores are very good and RandomForest Classifier is the best among them. \n\n- For this particular problem, in the problem statement it is mentioned - \" For technical reasons, the number of h events is underestimated. In the real data, the h class represents the majority of the events. The simple classification accuracy is not meaningful for this data, since classifying a background event as signal is worse than classifying a signal event as background. For comparison of different classifiers an ROC curve has to be used. The relevant points on this curve are those, where the probability of accepting a background event as signal is below one of the following thresholds: 0.01, 0.02, 0.05, 0.1, 0.2 depending on the required quality of the sample of the accepted events for different experiments.\"  -- This means that we need to supress/reject the background as much as we can. We cannot afford of mis-identifying a hadron as gamma. In this case we need to take care of 'false positive' outcomes and minimize it as far as possible. So, we should go with 'precision' as the metric for this problem.More is the precision, lower is the misidentification of false positives. if we compare the classification matrix for the models used, it is seen, that all of the models give a good precision. As a cost we are loosing signal which we can see from the 'recall' score. \n\n- Also, looking at the PR-curve, it can be observed that for recall > 0.9 and precision > 0.8, the gammas and hadrons are identified properly.  \n\nThis is the basic understanding this far. \n  \nLet us try to improve the models as step by step discussed below.   \n   \n1. Let us perform Stratified K-Fold cross validation for RandomForest case and hypertune the parameters to improve the model. \n2. We can also try upsampling and compare the results and see if the model has improved. ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Finding best models and best parameters using Cross validation and GridSearch","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:27.525381Z","iopub.execute_input":"2023-03-29T09:53:27.525741Z","iopub.status.idle":"2023-03-29T09:53:27.530601Z","shell.execute_reply.started":"2023-03-29T09:53:27.525709Z","shell.execute_reply":"2023-03-29T09:53:27.529234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter tuning and cross validation for RandomForest model. \n\nrf1 = RandomForestClassifier()\nparams = {'n_estimators' : list(range(100, 500, 100)),\n          'criterion' : ['gini', 'entropy']}\n\ncv = StratifiedKFold(n_splits=5, random_state = None, shuffle = False)\n\nclf=GridSearchCV(rf1, params, cv = cv,n_jobs=-1, scoring='recall')","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:27.531856Z","iopub.execute_input":"2023-03-29T09:53:27.532883Z","iopub.status.idle":"2023-03-29T09:53:27.544568Z","shell.execute_reply.started":"2023-03-29T09:53:27.532835Z","shell.execute_reply":"2023-03-29T09:53:27.543444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:53:27.546761Z","iopub.execute_input":"2023-03-29T09:53:27.547354Z","iopub.status.idle":"2023-03-29T09:56:33.128382Z","shell.execute_reply.started":"2023-03-29T09:53:27.547309Z","shell.execute_reply":"2023-03-29T09:56:33.127164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_rf_gs = clf.predict(X_test)\npred_prob_rf_gs = clf.predict_proba(X_test)[:, 0]\npred_prob_rf_gamma_gs =  clf.predict_proba(X_test)[:, 1]","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:56:33.130180Z","iopub.execute_input":"2023-03-29T09:56:33.131112Z","iopub.status.idle":"2023-03-29T09:56:34.622895Z","shell.execute_reply.started":"2023-03-29T09:56:33.131068Z","shell.execute_reply":"2023-03-29T09:56:34.621638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred_rf_gs))\nprint(confusion_matrix(y_test, y_pred_rf_gs))","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:56:34.624324Z","iopub.execute_input":"2023-03-29T09:56:34.624664Z","iopub.status.idle":"2023-03-29T09:56:34.647584Z","shell.execute_reply.started":"2023-03-29T09:56:34.624633Z","shell.execute_reply":"2023-03-29T09:56:34.646476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets find the ROC curve and AUC score for the above two models. \n\n#Next we would like to do random oversampling and see if the result improves.","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:56:34.649036Z","iopub.execute_input":"2023-03-29T09:56:34.649382Z","iopub.status.idle":"2023-03-29T09:56:34.654185Z","shell.execute_reply.started":"2023-03-29T09:56:34.649351Z","shell.execute_reply":"2023-03-29T09:56:34.653072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting roc curve and finding auc score : \n\nrf_fpr_gs, rf_tpr_gs, rf_threshold_gs = roc_curve(y_test, pred_prob_rf_gamma_gs, pos_label=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:56:34.656176Z","iopub.execute_input":"2023-03-29T09:56:34.656606Z","iopub.status.idle":"2023-03-29T09:56:34.668838Z","shell.execute_reply.started":"2023-03-29T09:56:34.656566Z","shell.execute_reply":"2023-03-29T09:56:34.667394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(rf_fpr_gs, rf_tpr_gs, color  = 'red', label='Random Forest Classifier')\n\nplt.title('ROC - After Grid Search')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:56:34.670527Z","iopub.execute_input":"2023-03-29T09:56:34.671084Z","iopub.status.idle":"2023-03-29T09:56:34.964058Z","shell.execute_reply.started":"2023-03-29T09:56:34.671039Z","shell.execute_reply":"2023-03-29T09:56:34.962951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# auc score : \nauc_rf_gs = roc_auc_score(y_test, pred_prob_rf_gamma_gs)\n\nprint('After Grid Search')\nprint(f'Auc score for Random Forest Classifier : {round(auc_rf_gs, 3)}')","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:56:34.965332Z","iopub.execute_input":"2023-03-29T09:56:34.967420Z","iopub.status.idle":"2023-03-29T09:56:34.980076Z","shell.execute_reply.started":"2023-03-29T09:56:34.967387Z","shell.execute_reply":"2023-03-29T09:56:34.979128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# P-R after grid search : \n\nprecision_rf1_gs, recall_rf1_gs, threshold_rf1_gs = precision_recall_curve(y_test, pred_prob_rf_gs, pos_label = 0)\nprecision_rf0_gs, recall_rf0_gs, threshold_rf0_gs = precision_recall_curve(y_test, pred_prob_rf_gamma_gs, pos_label = 1)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:56:34.981583Z","iopub.execute_input":"2023-03-29T09:56:34.981934Z","iopub.status.idle":"2023-03-29T09:56:34.991829Z","shell.execute_reply.started":"2023-03-29T09:56:34.981904Z","shell.execute_reply":"2023-03-29T09:56:34.990699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\n\nplt.plot(precision_rf1_gs, recall_rf1_gs, color='red', label='RF - Hadrons')\nplt.plot(precision_rf0_gs, recall_rf0_gs, color='red', linestyle = 'dashed' , label='RF - Gammas')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend(loc=\"lower left\")\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:56:34.993319Z","iopub.execute_input":"2023-03-29T09:56:34.993621Z","iopub.status.idle":"2023-03-29T09:56:35.304267Z","shell.execute_reply.started":"2023-03-29T09:56:34.993594Z","shell.execute_reply":"2023-03-29T09:56:35.303056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Comment:** \n\nUsing GridSearch the result didn't improve significantly. \n\n\n## Next... \n\n- We found that the RandomForestClassifier perfoms best. Now we need to train the model with equal numbers of hadrons and gammas and then test on the test data as we have discussed earlier.\n\n- The very usual approach is to train the model using same number of hadron and gamma data and predict the test data. So, in this case we will upsample the hadron data or downsample the gamma data so that there are same number of tagged data for hadrons and gamma. With these upsampled/downsampled data we will train the model and use the actual test data to predict and study the metric.\n\n- In this particular notebook we will perform oversampling of data and will use RandomForestClassifier model for prediction. \n(Downsampling is not done, as we loose the data information)","metadata":{}},{"cell_type":"markdown","source":"### Oversampling :","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\nfrom collections import Counter","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:56:35.305846Z","iopub.execute_input":"2023-03-29T09:56:35.306314Z","iopub.status.idle":"2023-03-29T09:56:35.312296Z","shell.execute_reply.started":"2023-03-29T09:56:35.306269Z","shell.execute_reply":"2023-03-29T09:56:35.310985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os = RandomOverSampler(sampling_strategy = 'minority')\nX_train_ns,y_train_ns = os.fit_resample(X_train,y_train)\nprint(\"The number of classes before fit {}\".format(y_train.value_counts()))\nprint(\"The number of classes after fit {}\".format(y_train_ns.value_counts()))","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:56:35.313703Z","iopub.execute_input":"2023-03-29T09:56:35.314068Z","iopub.status.idle":"2023-03-29T09:56:35.343249Z","shell.execute_reply.started":"2023-03-29T09:56:35.314039Z","shell.execute_reply":"2023-03-29T09:56:35.342163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:56:35.344701Z","iopub.execute_input":"2023-03-29T09:56:35.345491Z","iopub.status.idle":"2023-03-29T09:56:35.356289Z","shell.execute_reply.started":"2023-03-29T09:56:35.345448Z","shell.execute_reply":"2023-03-29T09:56:35.355005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf1_ns = RandomForestClassifier()\nparams_ns = {'n_estimators' : list(range(100, 500, 100)),\n          'criterion' : ['gini', 'entropy']}\n\ncv_ns = StratifiedKFold(n_splits=5, random_state = None, shuffle = False)\n\nclf_ns=GridSearchCV(rf1_ns, params_ns, cv = cv_ns,n_jobs=-1, scoring='precision')\n\n\n#rf_os = RandomForestClassifier()\n#rf_os.fit(X_train_ns, y_train_ns)\n\nclf_ns.fit(X_train_ns, y_train_ns)\npred_rf_os = clf_ns.predict(X_test)\npred_prob_rf_os = clf_ns.predict_proba(X_test)[:, 1]\n\nprint(classification_report(y_test, pred_rf_os))\nprint(confusion_matrix(y_test, pred_rf_os))","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:56:35.358015Z","iopub.execute_input":"2023-03-29T09:56:35.358549Z","iopub.status.idle":"2023-03-29T09:59:55.355317Z","shell.execute_reply.started":"2023-03-29T09:56:35.358477Z","shell.execute_reply":"2023-03-29T09:59:55.354001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ROC curve and AUC score:** \n\n","metadata":{}},{"cell_type":"code","source":"# roc curve\nrf_fpr_ns, rf_tpr_ns, rf_threshold_ns = roc_curve(y_test, pred_prob_rf_os, pos_label=1)\nplt.plot(rf_fpr_ns, rf_tpr_ns, color  = 'red', label='Random Forest Classifier')\n\nplt.title('ROC - RandomOverSampler')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:59:55.357055Z","iopub.execute_input":"2023-03-29T09:59:55.357522Z","iopub.status.idle":"2023-03-29T09:59:55.645296Z","shell.execute_reply.started":"2023-03-29T09:59:55.357478Z","shell.execute_reply":"2023-03-29T09:59:55.643923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# auc score : \nauc_rf_gs = roc_auc_score(y_test, pred_prob_rf_os)\n\nprint('After RandomOverSampler')\nprint(f'Auc score for Random Forest Classifier : {round(auc_rf_gs, 3)}')","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:59:55.647114Z","iopub.execute_input":"2023-03-29T09:59:55.648112Z","iopub.status.idle":"2023-03-29T09:59:55.660642Z","shell.execute_reply.started":"2023-03-29T09:59:55.648065Z","shell.execute_reply":"2023-03-29T09:59:55.659248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SMOTEK :","metadata":{}},{"cell_type":"code","source":"from imblearn.combine import SMOTETomek","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:59:55.662298Z","iopub.execute_input":"2023-03-29T09:59:55.663186Z","iopub.status.idle":"2023-03-29T09:59:55.669385Z","shell.execute_reply.started":"2023-03-29T09:59:55.663108Z","shell.execute_reply":"2023-03-29T09:59:55.668220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sm = SMOTETomek(sampling_strategy = 'minority')\nX_train_sm,y_train_sm = sm.fit_resample(X_train,y_train)\nprint(\"The number of classes before fit {}\".format(y_train.value_counts()))\nprint(\"The number of classes after fit {}\".format(y_train_sm.value_counts()))","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:59:55.670728Z","iopub.execute_input":"2023-03-29T09:59:55.671039Z","iopub.status.idle":"2023-03-29T09:59:56.058662Z","shell.execute_reply.started":"2023-03-29T09:59:55.671011Z","shell.execute_reply":"2023-03-29T09:59:56.057320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf1_sm = RandomForestClassifier()\nparams_sm = {'n_estimators' : list(range(100, 500, 100)),\n          'criterion' : ['gini', 'entropy']}\n\ncv_sm = StratifiedKFold(n_splits=5, random_state = None, shuffle = False)\n\nclf_sm = GridSearchCV(rf1_sm, params_sm, cv = cv_sm,n_jobs=-1, scoring='precision')\n\n\n#rf_os = RandomForestClassifier()\n#rf_os.fit(X_train_ns, y_train_ns)\ny_train_sm1 = np.ravel(y_train_sm)\nclf_sm.fit(X_train_sm, y_train_sm1)\npred_rf_sm = clf_sm.predict(X_test)\npred_prob_rf_sm = clf_sm.predict_proba(X_test)[:, 1]\n\nprint(classification_report(y_test, pred_rf_sm))\nprint(confusion_matrix(y_test, pred_rf_sm))","metadata":{"execution":{"iopub.status.busy":"2023-03-29T09:59:56.060245Z","iopub.execute_input":"2023-03-29T09:59:56.061249Z","iopub.status.idle":"2023-03-29T10:03:14.376490Z","shell.execute_reply.started":"2023-03-29T09:59:56.061202Z","shell.execute_reply":"2023-03-29T10:03:14.375086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ROC curve and AUC score :**","metadata":{}},{"cell_type":"code","source":"# roc curve\nrf_fpr_sm, rf_tpr_sm, rf_threshold_sm = roc_curve(y_test, pred_prob_rf_sm, pos_label=1)\nplt.plot(rf_fpr_sm, rf_tpr_sm, color  = 'red', label='Random Forest Classifier')\n\nplt.title('ROC - SMOTETomek')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T10:03:14.377867Z","iopub.execute_input":"2023-03-29T10:03:14.378224Z","iopub.status.idle":"2023-03-29T10:03:14.658233Z","shell.execute_reply.started":"2023-03-29T10:03:14.378192Z","shell.execute_reply":"2023-03-29T10:03:14.657044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# auc score : \nauc_rf_gs = roc_auc_score(y_test, pred_prob_rf_sm)\n\nprint('After SMOTETomek')\nprint(f'Auc score for Random Forest Classifier : {round(auc_rf_gs, 3)}')","metadata":{"execution":{"iopub.status.busy":"2023-03-29T10:03:14.659806Z","iopub.execute_input":"2023-03-29T10:03:14.660127Z","iopub.status.idle":"2023-03-29T10:03:14.671741Z","shell.execute_reply.started":"2023-03-29T10:03:14.660099Z","shell.execute_reply":"2023-03-29T10:03:14.670472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Threshold Tuning : \nOnce we have the model and understood the ROC and PR curve, the next job is to find the optimum value of the threshold which leads to the best precision-recall trade-off. Mostly this incorporates the knowledge of domain expert. \nBut in this notebook we will just go with the flow. As we have discussed earlier, that for this problem precision is very important and hence we will tune the threshold to obtain maximum precision without loosing recall. It is observed that though the AUC scores for the Random Forest Grid Search Model, Oversampler and SMOTETomek are nearly equal but the classification metric is better for the SMOTETomek model. So, in this notebook we will do this step for the \nSMOTETomek model. \n\nTwo common approaches will be perfomed: \n1. G mean \n2. Youden's statistic","metadata":{}},{"cell_type":"markdown","source":"**Threshold for ROC curve :**","metadata":{}},{"cell_type":"code","source":"# using Gmean : \n# finding out max gmean and the corresponding threshold and tpr and fpr\n\ndef get_gmean_threshold_fpr_tpr(tpr, fpr, threshold):\n    gmean  = np.sqrt(tpr* (1 - fpr))\n    opt_gmean = np.max(gmean)\n    opt_gmean_index = np.argmax(gmean)\n    #opt_mean_index = np.where(opt_gmean)\n    opt_threshold = threshold[opt_gmean_index]\n    opt_fpr = round(fpr[opt_gmean_index], 5)\n    opt_tpr = round(tpr[opt_gmean_index], 5)\n    \n    return gmean, opt_gmean, opt_gmean_index, opt_threshold, opt_fpr, opt_tpr\n\ngmean, opt_gmean, opt_gmean_index,opt_threshold, opt_fpr, opt_tpr  = get_gmean_threshold_fpr_tpr(rf_tpr_sm, rf_fpr_sm, rf_threshold_sm)\nprint(f'Optimum gmean: {opt_gmean}')\nprint(f'Index for optimum mean : {opt_gmean_index}')\nprint(f'Threshold corresponding to Optimum Gmean :{opt_threshold}') \nprint(f'FPR corresponding to Optimum Gmean :  {opt_fpr}')\nprint(f'TPR corresponding to Optimum Gmean : {opt_tpr}')","metadata":{"execution":{"iopub.status.busy":"2023-03-29T10:13:32.025055Z","iopub.execute_input":"2023-03-29T10:13:32.025689Z","iopub.status.idle":"2023-03-29T10:13:32.038467Z","shell.execute_reply.started":"2023-03-29T10:13:32.025640Z","shell.execute_reply":"2023-03-29T10:13:32.037231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting : \n\nfig, axes = plt.subplots(1,2, figsize=(8,3), tight_layout = True )\n\naxes[0].plot(rf_threshold_sm, gmean, color = 'blue')\naxes[0].plot(opt_threshold, opt_gmean, color = 'black', \n         marker = \".\", markersize = 12)\naxes[0].set_title('Gmean vs threshold values')\naxes[0].set_xlabel('Threshold values')\naxes[0].set_ylabel('Gmean')\n#axes[0].show()\n\n\n\naxes[1].plot(rf_fpr_gs, rf_tpr_gs, color = 'red')\naxes[1].plot(opt_fpr, opt_tpr, color = 'black', marker = '*', \n         markersize = 12, label = 'RandomForestClassifier')\n\naxes[1].set_title('ROC - SMOTETomek with threshold values')\naxes[1].set_xlabel('False Positive Rate')\naxes[1].set_ylabel('True Positive Rate')\naxes[1].legend(loc=\"lower right\")\n#axes[1].show()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T10:13:37.203445Z","iopub.execute_input":"2023-03-29T10:13:37.203917Z","iopub.status.idle":"2023-03-29T10:13:37.766765Z","shell.execute_reply.started":"2023-03-29T10:13:37.203881Z","shell.execute_reply":"2023-03-29T10:13:37.765549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference**   \nWith is exercise we first find the optimum threshold value for this problem from gmean vs threshold data (shown by 'dot' on the LHS plot). The optimum value for \nthreshold is 0.58. Next we try to find out the optimum tpr and fpr values corresponding to the optimum threshold value = 0.58. This is shown by the 'star' marker on the RHS plot. The other values are listed above.   \nSo given this problem, after calculating the probabilities of outputs, one can use threshold value as 0.58 and find out the two classes. We expect that these choices will lead to the best predictions.","metadata":{}},{"cell_type":"code","source":"# using Youden's statistic\n\ndef get_ystat_threshold_fpr_tpr(tpr, fpr, threshold):\n    ystat  = tpr - fpr\n    opt_ystat = np.max(ystat)\n    opt_ystat_index = np.argmax(ystat)\n    #opt_ystat_index = np.where(opt_ystat)\n    opt_threshold = threshold[opt_ystat_index]\n    opt_fpr = fpr[opt_ystat_index]\n    opt_tpr = tpr[opt_ystat_index]\n    \n    return ystat, opt_ystat, opt_ystat_index, opt_threshold, opt_fpr, opt_tpr\n\nystat, opt_ystat, opt_ystat_index,opt_threshold, opt_fpr, opt_tpr  = get_ystat_threshold_fpr_tpr(rf_tpr_sm, rf_fpr_sm, rf_threshold_sm)\nprint(f'Optimum ystat: {opt_ystat}')\nprint(f'Index for optimum mean : {opt_ystat_index}')\nprint(f'Threshold corresponding to Optimum Gmean :{opt_threshold}') \nprint(f'FPR corresponding to Optimum Gmean :  {opt_fpr}')\nprint(f'TPR corresponding to Optimum Gmean : {opt_tpr}')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-29T10:14:25.775196Z","iopub.execute_input":"2023-03-29T10:14:25.775615Z","iopub.status.idle":"2023-03-29T10:14:25.786641Z","shell.execute_reply.started":"2023-03-29T10:14:25.775581Z","shell.execute_reply":"2023-03-29T10:14:25.785111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Results after threshold tuning : \nNow,  we need to plugin this threshold value for the prediction and find out whether the prediction statistics improve or not.","metadata":{}},{"cell_type":"code","source":"#y_pred_new = (clf.predict_proba(X_test)[:,1] >= opt_threshold).astype(bool) # set threshold as 0.3\ny_pred_new = (pred_prob_rf_gamma_gs >= opt_threshold).astype(bool)\ny_pred_new","metadata":{"execution":{"iopub.status.busy":"2023-03-29T10:15:03.025682Z","iopub.execute_input":"2023-03-29T10:15:03.026101Z","iopub.status.idle":"2023-03-29T10:15:03.035235Z","shell.execute_reply.started":"2023-03-29T10:15:03.026069Z","shell.execute_reply":"2023-03-29T10:15:03.034041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, np.ravel(y_pred_new)))\nprint(confusion_matrix(y_test, np.ravel(y_pred_new)))","metadata":{"execution":{"iopub.status.busy":"2023-03-29T10:15:05.922236Z","iopub.execute_input":"2023-03-29T10:15:05.922626Z","iopub.status.idle":"2023-03-29T10:15:05.950736Z","shell.execute_reply.started":"2023-03-29T10:15:05.922597Z","shell.execute_reply":"2023-03-29T10:15:05.949889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we take a look at the confusion matrix, we can observe that number of misidentifications are reduced. The metrics have improved a bit in comparison to the SMOTETomek model but they have improved significantly in comparison to simple random forest classifer or adaboost or random forest with grid search.","metadata":{}},{"cell_type":"markdown","source":"## Conclusions :\nIn this project, the main aim was to identify gamma in a haystack of hadrons. The dataset contains more gamma data than hadron data. Looking at the pairplot we performed the classification task using the Ensemble techniques. Looking at the ROC curve, AUC score and PR curve we can say that RandomForest Classifier did the best job. The hyperparameter tuning was also performed but the result did not improve much. As there were a difference in number of hadron and gamma data, the upsampling technique was also perfomed using RandomOverSampler and SmotekTomek. The AUC scores have not improve much from the initial one, though if we take a look at the precision-recall values, SMOTETomek has the best one. \nNext we also performed the threshold tuning technique to improve predictions. As \nthe metric for SMOTETomek is the best among all the models discussed, we decided to perform the threshold tuning for this model. We obtained the optimum threshold for this case and using this threshold value we obtain predictions. This time the metrics and the confusion matrix we get is better than what we had earlier.  ","metadata":{}},{"cell_type":"markdown","source":"**References :**\n\n- https://machinelearningmastery.com/tune-learning-rate-for-gradient-boosting-with-xgboost-in-python/   \n\n- https://inria.github.io/scikit-learn-mooc/python_scripts/ensemble_hist_gradient_boosting.html  \n\n- https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/   \n\n- https://medium.com/@chaudhurysrijani/tuning-of-adaboost-with-computational-complexity-8727d01a9d20    \n\n- https://github.com/krishnaik06/Handle-Imbalanced-Dataset/blob/master/handling-imbalanced.ipynb    \n\n- https://www.kaggle.com/general/262007  \n\n- https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets  \n\n- https://www.kaggle.com/code/gargmanish/how-to-handle-imbalance-data-study-in-detail/notebook  \n\n\n-  https://neptune.ai/blog/evaluation-metrics-binary-classification \n\n- ROC curve\n - https://waterprogramming.wordpress.com/2021/02/08/how-do-we-deal-with-extreme-events-and-imbalanced-datasets-in-machine-learning/ \n\n - https://www.displayr.com/what-is-a-roc-curve-how-to-interpret-it/ \n\n - https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5  \n\n - https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/  \n\n - https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc   \n\n - https://www.statology.org/interpret-roc-curve/  \n\n\n- Precision Recall curve \n\n - https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#:~:text=The%20precision%2Drecall%20curve%20shows,a%20low%20false%20negative%20rate. \n\n - https://medium.com/@douglaspsteen/precision-recall-curves-d32e5b290248  \n\n - https://www.datascienceblog.net/post/machine-learning/interpreting-roc-curves-auc/  \n\n - https://analyticsindiamag.com/complete-guide-to-understanding-precision-and-recall-curves/  \n\n - https://www.geeksforgeeks.org/precision-recall-curve-ml/ \n\n - https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/  \n\n - https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/  \n\n - https://acutecaretesting.org/en/articles/precision-recall-curves-what-are-they-and-how-are-they-used  \n \n\n- Threshold tuning \n\n - https://towardsdatascience.com/optimal-threshold-for-imbalanced-classification-5884e870c293\n \n - https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n\n - https://towardsdatascience.com/finding-the-best-classification-threshold-for-imbalanced-classifications-with-interactive-plots-7d65828dda38 \n\n - https://www.yourdatateacher.com/2021/06/14/are-you-still-using-0-5-as-a-threshold/ \n\n - https://stats.stackexchange.com/questions/312119/reduce-classification-probability-threshold \n\n - https://pub.towardsai.net/improve-your-classification-models-with-threshold-tuning-bb69fca15114\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}